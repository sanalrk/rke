8.1.3.2.5 Grafana REPORT DOCUMENTATION BUG#
Starting from Grafana 5.0, it is possible to dynamically provision the data sources and dashboards via files. In a Kubernetes cluster, these files are provided via the utilization of ConfigMap, editing a ConfigMap will result by the modification of the configuration without having to delete/recreate the pod.

Configure Grafana provisioning

Create the default datasource configuration file grafana-datasources.yaml which point to our Prometheus server

kind: ConfigMap
apiVersion: v1
metadata:
  name: grafana-datasources
  namespace: monitoring
  labels:
     grafana_datasource: "1"
data:
  datasource.yaml: |-
    apiVersion: 1
    deleteDatasources:
      - name: Prometheus
        orgId: 1
    datasources:
    - name: Prometheus
      type: prometheus
      url: http://prometheus-server.monitoring.svc.cluster.local:80
      access: proxy
      orgId: 1
      isDefault: true
COPY CODE
Create the ConfigMap in Kubernetes cluster

kubectl create -f grafana-datasources.yaml
COPY CODE
Configure storage for the deployment

Choose among the options and uncomment the line in the config file. In production environments you must configure persistent storage.

Use an existing PersistentVolumeClaim

Use a StorageClass (preferred)

Create a file grafana-config-values.yaml with the appropriate values

# Configure admin password
adminPassword: <PASSWORD>

# Ingress configuration
ingress:
  enabled: true
  annotations:
    kubernetes.io/ingress.class: nginx
  hosts:
    - grafana.example.com
  tls:
    - hosts:
      - grafana.example.com
      secretName: monitoring-tls

# Configure persistent storage
persistence:
  enabled: true
  accessModes:
    - ReadWriteOnce
  ## Use a StorageClass
  storageClassName: my-storage-class
  ## Create a PersistentVolumeClaim of 10Gi
  size: 10Gi
  ## Use an existing PersistentVolumeClaim (my-pvc)
  #existingClaim: my-pvc

# Enable sidecar for provisioning
sidecar:
  datasources:
    enabled: true
    label: grafana_datasource
  dashboards:
    enabled: true
    label: grafana_dashboard
COPY CODE
Add SUSE helm charts repository

helm repo add suse https://kubernetes-charts.suse.com
COPY CODE
Deploy SUSE grafana helm chart and pass our configuration values file

helm install grafana suse/grafana \
--namespace monitoring \
--values grafana-config-values.yaml
COPY CODE
The result should be a running Grafana pod

kubectl -n monitoring get pod | grep grafana
NAME                                             READY     STATUS    RESTARTS   AGE
grafana-dbf7ddb7d-fxg6d                          3/3       Running   0          2m
COPY CODE
At this stage, Grafana should be accessible, depending on your network configuration

NodePort: https://grafana.example.com:32443

External IPs: https://grafana.example.com

LoadBalancer: https://grafana.example.com

Now you can add Grafana dashboards.

8.1.3.2.6 Adding Grafana Dashboards REPORT DOCUMENTATION BUG#
There are three ways to add dashboards to Grafana:

Deploy an existing dashboard from Grafana dashboards

Open the deployed Grafana in your browser and log in.

On the home page of Grafana, hover your mousecursor over the + button on the left sidebar and click on the import menuitem.

Select an existing dashboard for your purpose from Grafana dashboards. Copy the URL to the clipboard.

Paste the URL (for example) https://grafana.com/dashboards/3131 into the first input field to import the "Kubernetes All Nodes" Grafana Dashboard. After pasting in the url, the view will change to another form.

Now select the "Prometheus" datasource in the prometheus field and click on the import button.

The browser will redirect you to your newly created dashboard.

Use our pre-built dashboards to monitor the SUSE CaaS Platform system

# monitor SUSE CaaS Platform cluster
kubectl apply -f https://raw.githubusercontent.com/SUSE/caasp-monitoring/master/grafana-dashboards-caasp-cluster.yaml
# monitor SUSE CaaS Platform etcd cluster
kubectl apply -f https://raw.githubusercontent.com/SUSE/caasp-monitoring/master/grafana-dashboards-caasp-etcd-cluster.yaml
# monitor SUSE CaaS Platform nodes
kubectl apply -f https://raw.githubusercontent.com/SUSE/caasp-monitoring/master/grafana-dashboards-caasp-nodes.yaml
# monitor SUSE CaaS Platform namespaces
kubectl apply -f https://raw.githubusercontent.com/SUSE/caasp-monitoring/master/grafana-dashboards-caasp-namespaces.yaml
# monitor SUSE CaaS Platform pods
kubectl apply -f https://raw.githubusercontent.com/SUSE/caasp-monitoring/master/grafana-dashboards-caasp-pods.yaml
# monitor SUSE CaaS Platform certificates
kubectl apply -f https://raw.githubusercontent.com/SUSE/caasp-monitoring/master/grafana-dashboards-caasp-certificates.yaml
COPY CODE
Build your own dashboard Deploy your own dashboard by configuration file containing the dashboard definition.

Create your dashboard definition file as a ConfigMap, for example grafana-dashboards-caasp-cluster.yaml.

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboards-caasp-cluster
  namespace: monitoring
  labels:
     grafana_dashboard: "1"
data:
  caasp-cluster.json: |-
    {
      "__inputs": [
        {
          "name": "DS_PROMETHEUS",
          "label": "Prometheus",
          "description": "",
          "type": "datasource",
          "pluginId": "prometheus",
          "pluginName": "Prometheus"
        }
      ],
      "__requires": [
        {
          "type": "grafana",
[...]
continues with definition of dashboard JSON
[...]
COPY CODE
Apply the ConfigMap to the cluster.

kubectl apply -f grafana-dashboards-caasp-cluster.yaml
COPY CODE
